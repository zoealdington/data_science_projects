{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Lesson 14 - Latent Variables and Natural Language Processing\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Activity: Twitter Lab\n",
    "In this exercise, we will compare some of the classical NLP tools from the last class with these more modern latent variable techniques.  We will do this by comparing information extraction on Twitter using two different methods.\n",
    "\n",
    "There is a pre-existing file of captured tweets you can use.  It is located in the datasets folder of the class repo. \n",
    "\n",
    "The sample `captured-tweets.txt` dataset in the repo was generated by collecting ~5000 tweets from the TwitterAPI using the keywords:\n",
    "- `Google`\n",
    "- `Microsoft`\n",
    "- `Goldman Sachs`\n",
    "- `Citigroup`\n",
    "- `Tesla`\n",
    "- `Verizon`\n",
    "- `Syria`\n",
    "- `Iran`\n",
    "- `Israel`\n",
    "- `Iraq`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayham\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "# Unicode Handling\n",
    "from __future__ import unicode_literals\n",
    "import codecs\n",
    "\n",
    "import numpy as np\n",
    "import gensim\n",
    "\n",
    "# spacy is used for pre-processing and traditional NLP\n",
    "import spacy\n",
    "from spacy.en import English\n",
    "\n",
    "nlp_toolkit = spacy.load('en')\n",
    "\n",
    "# Gensim is used for LDA and word2vec\n",
    "from gensim.models.word2vec import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loading the tweet data\n",
    "filename = 'dataset/captured-tweets.txt'\n",
    "tweets = []\n",
    "for tweet in codecs.open(filename, 'r', encoding=\"utf-8\"):\n",
    "    tweets.append(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example for nlp_toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPE London\n",
      "GPE the United Kingdom\n"
     ]
    }
   ],
   "source": [
    "doc = nlp_toolkit(u'London is a big city in the United Kingdom.')\n",
    "for ent in doc.ents:\n",
    "    print(ent.label_, ent.text)\n",
    "    # GPE London\n",
    "    # GPE United Kingdom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1a\n",
    "\n",
    "Write a function that can take a sentence parsed by `spacy` and identify if it mentions a company named 'Google'. Remember, `spacy` can find entities and codes them as `ORG` if they are a company. Look at the slides for class 13 if you need a hint.\n",
    "\n",
    "### Bonus (1b)\n",
    "\n",
    "Parameterise the company name so that the function works for any company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mentions_company(parsed):\n",
    "    for entity in parsed.ents:\n",
    "        if entity.text == \"Google\" and entity.label_ == 'ORG':\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# 1b\n",
    "\n",
    "def mentions_company(parsed, company='Google'):\n",
    "    for entity in parsed.ents:\n",
    "        if entity.text == company and entity.label_ == 'ORG':\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1c\n",
    "\n",
    "Write a function that can take a sentence parsed by `spacy` \n",
    "and return the verbs of the sentence (preferably lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_actions(parsed):\n",
    "    actions = []\n",
    "    for el in parsed:\n",
    "        if el.pos == spacy.parts_of_speech.VERB:\n",
    "            actions.append(el.text)\n",
    "    return actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1d\n",
    "For each tweet, parse it using spacy and print it out if the tweet has 'Google' as company and 'spying' or 'announce' as a verb. You'll need to use your `mentions_company` and `get_actions` functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft joins Google and Facebook with warnings to users about government spying https://t.co/tXjvgeHFOu https://t.co/TW7aJb37q9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for tweet in tweets:\n",
    "    parsed = nlp_toolkit(tweet)\n",
    "    if mentions_company(parsed, 'Google'):\n",
    "        actions = get_actions(parsed)        \n",
    "        if 'spying' in actions or 'announce' in actions:\n",
    "            print(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['joins', 'spying']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @business: Where Amazon, Microsoft, Google, IBM and DigitalOcean are building data centers https://t.co/VX047Jm9tq https://t.co/opTaZzO7â€¦\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for tweet in tweets:\n",
    "    parsed = nlp_toolkit(tweet)\n",
    "    if mentions_company(parsed, 'Google'):\n",
    "        actions = get_actions(parsed)\n",
    "        if 'release' in actions or 'announce' in actions or 'building' in actions:\n",
    "            print(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Exercise 1e\n",
    "Write a function that identifies countries - HINT: the entity label for countries is GPE (or GeoPolitical Entity)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mentions_country(parsed, country):\n",
    "    for entity in parsed.ents:\n",
    "        if entity.text == country and entity.label_ == 'GPE':\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1f\n",
    "\n",
    "Re-run (d) to find country tweets that discuss 'Iran' announcing or releasing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @cerenomri: \"Literally every US ally in Mideast is on brink of hot war w/ Iran, so we're going to release $100 billion to Iran this montâ€¦\n",
      "\n",
      "GOBE! Iran warns Nigeria to release Shiite leader El-Zakzaky - SEE https://t.co/TRshnC6sVU\n",
      "\n",
      "GOBE! Iran warns Nigeria to release Shiite leader El-Zakzaky - SEE https://t.co/SlvcQtk3vE\n",
      "\n",
      "RT @cerenomri: \"Literally every US ally in Mideast is on brink of hot war w/ Iran, so we're going to release $100 billion to Iran this montâ€¦\n",
      "\n",
      "Hhmmm. Iran claiming to have 'warned Nigeria' to release detained Shiite leader.... @afalli\n",
      "\n",
      "RT @cerenomri: \"Literally every US ally in Mideast is on brink of hot war w/ Iran, so we're going to release $100 billion to Iran this montâ€¦\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for tweet in tweets:\n",
    "    parsed = nlp_toolkit(tweet)\n",
    "\n",
    "    if mentions_country(parsed, 'Iran'):\n",
    "        actions = get_actions(parsed)\n",
    "        if 'release' in actions or 'announce' in actions:\n",
    "            print(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "Build a word2vec model of the tweets we have collected using gensim.\n",
    "First take the collection of tweets and tokenize them using spacy.\n",
    "\n",
    "### Exercise 2a:\n",
    "* Think about how this should be done. \n",
    "* Should you only use upper-case or lower-case? \n",
    "* Should you remove punctuations or symbols? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_split = [[x.text if x.pos != spacy.parts_of_speech.VERB else x.lemma_ \n",
    "                for x in nlp_toolkit(t)] for t in tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I made a(n) Small Tourmaline in Paradise Island! https://t.co/cAoW1b6DRc #Gameinsight #Androidgames #Android\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['I',\n",
       "  'make',\n",
       "  'a(n',\n",
       "  ')',\n",
       "  'Small',\n",
       "  'Tourmaline',\n",
       "  'in',\n",
       "  'Paradise',\n",
       "  'Island',\n",
       "  '!',\n",
       "  'https://t.co/cAoW1b6DRc',\n",
       "  '#',\n",
       "  'Gameinsight',\n",
       "  '#',\n",
       "  'Androidgames',\n",
       "  '#',\n",
       "  'Android',\n",
       "  '\\n']]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_split[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2b:\n",
    "Build a word2vec model.\n",
    "Test the window size as well - this is how many surrounding words need to be used to model a word. What do you think is appropriate for Twitter? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Word2Vec(text_split, size=100, window=4, min_count=5, workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2c:\n",
    "Test your word2vec model with a few similarity functions. \n",
    "* Find words similar to 'tweet'.\n",
    "* Find words similar to 'rank'.\n",
    "* Find words similar to 'Google'.\n",
    "* Find words similar to 'Syria'. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('10', 0.999434769153595),\n",
       " ('help', 0.9993937611579895),\n",
       " ('join', 0.9993391633033752),\n",
       " ('could', 0.9993309378623962),\n",
       " ('say', 0.9993267059326172),\n",
       " ('every', 0.9993239641189575),\n",
       " ('Rouhani', 0.9993118047714233),\n",
       " ('please', 0.9993070960044861),\n",
       " ('US', 0.9993057250976562),\n",
       " ('3', 0.9992966055870056)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['tweet'],topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('partners', 0.9965410232543945),\n",
       " ('refuse', 0.9965380430221558),\n",
       " ('The', 0.9965197443962097),\n",
       " ('NEW', 0.9964765310287476),\n",
       " ('Day', 0.996303379535675),\n",
       " ('In', 0.9962840676307678),\n",
       " ('Syrian', 0.9962807297706604),\n",
       " ('No', 0.9962160587310791),\n",
       " ('Tesla', 0.9962055087089539),\n",
       " ('How', 0.9961835741996765)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['rank'],topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Play', 0.9933983683586121),\n",
       " ('ROYALTY', 0.9928666949272156),\n",
       " ('famous', 0.9915315508842468),\n",
       " ('juice', 0.9911171197891235),\n",
       " ('RADIO', 0.9887184500694275),\n",
       " ('https://t.co/6Y96MXdAOD', 0.988685667514801),\n",
       " ('@BrookingsInst', 0.9885120987892151),\n",
       " ('S', 0.9880359768867493),\n",
       " ('Playï¼šhttps://t.co', 0.9875374436378479),\n",
       " ('APPS', 0.9874345064163208)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['Google'],topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('opposition', 0.999240517616272),\n",
       " ('Russia', 0.9984389543533325),\n",
       " ('death', 0.9973208904266357),\n",
       " ('Arab', 0.9973099231719971),\n",
       " ('Ads', 0.9971376657485962),\n",
       " ('0161', 0.9969374537467957),\n",
       " ('in', 0.9969058632850647),\n",
       " ('conference', 0.9967876672744751),\n",
       " ('+', 0.9966884851455688),\n",
       " ('art', 0.9966536164283752),\n",
       " ('human', 0.996423602104187),\n",
       " ('benefit', 0.9963943958282471)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['Syria'],topn=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2d\n",
    "\n",
    "Adjust the choices in (b) and (c) as necessary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "\n",
    "Filter tweets to those that mention 'Iran' or similar entities and 'plan' or similar entities.\n",
    "* Do this using just spacy.\n",
    "* Do this using word2vec similarity scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using word2vec similarity scores\n",
    "def tweet_sim(word_1,word_2,threshold_1=0.99,threshold_2=0.99):\n",
    "    tweet_list = []\n",
    "    i = 0\n",
    "    for tweet in tweets[:200]:\n",
    "        tweet_sublist = []\n",
    "        parsed = nlp_toolkit(tweet)\n",
    "\n",
    "        similarity_to_1 = max([model.similarity(word_1, tok.text) for tok in parsed if tok.text in model.wv.vocab])\n",
    "        similarity_to_2 = max([model.similarity(word_2, tok.text) for tok in parsed if tok.text in model.wv.vocab])\n",
    "        if similarity_to_1 > threshold_1 and similarity_to_2 > threshold_2:\n",
    "            tweet_sublist.append(i)\n",
    "            tweet_sublist.append([similarity_to_1, similarity_to_2])\n",
    "            tweet_sublist.append(tweet)\n",
    "            tweet_list.append(tweet_sublist)\n",
    "            i += 1\n",
    "        \n",
    "    print('tweets above threshold:', i)\n",
    "    return tweet_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweets above threshold: 58\n"
     ]
    }
   ],
   "source": [
    "list_google_find = tweet_sim('Google','find',0.99,0.995)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Claim your Google Play Gift Card Code... https://t.co/ySYH1x5kQl #amazon #itunes #googlâ€¦ https://t.co/ayDI4X1FKO\\n',\n",
       " \"I've entered to win a Google Nexus 6P from  !    https://t.co/4vFHfhaBey\\n\",\n",
       " \"RT @kamcb29: I've entered to win a Google Nexus 6P from @MakeUseOf ! https://t.co/o30B9xG6Dx #giveaway #competition\\n\",\n",
       " 'I LOVE your Google plus page with the other girls! ðŸ’œðŸ˜†\\n',\n",
       " \"After I've Google &amp; read a ton of articles on the same subject, I remember, I could've just searched YouTube for this shit ðŸ˜ \\n\",\n",
       " 'RT @ShowerThoughtts: Apple has \"air\", Amazon has \"Fire\", Google has \"earth\", why doesn\\'t Microsoft have \"water\"?\\n',\n",
       " \"-Looks up on Google 'MikexJeremy' secretly- &lt;33 ;) [@FnafSchimdt,@MikeSchmit10,]#SenpaiBot~\\n\",\n",
       " 'RT @_silentbent_: Go support @dadeputy single \"It\\'s Okay\" feat @jaesongreen on iTunes,Googleâ€¦ https://t.co/WPc1jwFLs0\\n',\n",
       " 'Ever wanted to become a Google Small Business Advisor? Now you can! https://t.co/fcOkq6srSX\\n',\n",
       " 'Top Android Apps (without all the games) revealed in hidden Google Play Store link -â€¦ https://t.co/7ZSs9MkcLm #Android #India\\n']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[lg[2] for lg in list_google_find][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweets above threshold: 11\n"
     ]
    }
   ],
   "source": [
    "list_iran_plan = tweet_sim('Iran','plan',0.99,0.995)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RT https://t.co/HqV9jSb6In Android application related to google maps -- 2 by nsatheeshk: Need to update the Android Mobil... â€¦\\n',\n",
       " 'LebanonHashtag: RT probrandz: #Facebook Open Sources Artificial #Intelligence Servers Before #Google | Re/code https://t.co/f8RTJxEzSx\\n',\n",
       " 'KalGuntuku: RT bunnymiilk \"RT 30seclovelive: [RT to win!] 30 Seconds of Love Live! 5k Followers Giveaway #1: $25 iTunes/Google Play gift caâ€¦\\n',\n",
       " '[Minecraft] I google \"Natural arch\" and a Minecraft image popped up for a real geographical scenic spot by Skandalâ€¦ https://t.co/9ZZrZrfJpP\\n',\n",
       " 'LebanonHashtag: RT probrandz: #Facebook Open Sources Artificial #Intelligence Servers Before #Google | Re/code https://t.co/VgWBxAG52q\\n',\n",
       " 'Ford adds Apple CarPlay and Android Auto to Sync 3,... https://t.co/NSPCS9KHWE #google | https://t.co/MZBQSll3dP https://t.co/tHKibTMDlU\\n',\n",
       " \"RT @dinowoowife: [MY] JIMIN 2016 'RISE' stock sale by MINingful moment @miningfulmoment â™¥ https://t.co/DwRaGK45D3 https://t.co/Nh04n1sB5b\\n\",\n",
       " \"RT @f396: Iran blames America, Britain and 'Zionists' for Nimr execution - https://t.co/BwXEicgAOA via https://t.co/UjStGmTT2f\\n\",\n",
       " 'RT @f396: Saudi Arabia severs diplomatic ties with Iran over embassy fire - https://t.co/r0iZugJa3v via https://t.co/UjStGmTT2f\\n',\n",
       " \"RT @f396: 'Iran has a long record in attacking foreign diplomatic missions,' Saudi ... - https://t.co/3gaSRB3osT via https://t.co/UjStGmTT2f\\n\"]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[lg[2] for lg in list_iran_plan][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
